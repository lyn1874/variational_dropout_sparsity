{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is for learning both pytorch and variational dropout sparsifies deep neural network\n",
    "import math\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#from local_logger import Logger\n",
    "from torch.nn import Parameter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import imageio\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "CONV2D=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSVDO(nn.Module):\n",
    "    def __init__(self, in_features, out_features, threshold, bias=True):\n",
    "        super(LinearSVDO, self).__init__()\n",
    "        self.in_features = in_features  # the input dimension\n",
    "        self.out_features = out_features # the output dimension \n",
    "        self.threshold = threshold # the threshold that determines whether a neuron is set to be zero \n",
    "        \n",
    "        self.W = Parameter(torch.Tensor(out_features, in_features)) # so I guess it's output channel, inputchannel\n",
    "        self.log_sigma = Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.bias = Parameter(torch.Tensor(1, out_features)) # output channel, input channel ?\n",
    "        \n",
    "        print(\"The weight matrix\", self.W.shape)\n",
    "        print(\"The log sigma\", self.log_sigma.shape)\n",
    "        print(\"The bias term\", self.bias.shape)\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"This function is used to initialize the parameters\"\"\"\n",
    "        self.bias.data.zero_()\n",
    "        self.W.data.normal_(0, 0.02)  # the weight matrix follows a normal distribution with mean 0.0 and sigma 0.02\n",
    "        self.log_sigma.data.fill_(-5)  # the logsigma is initialized to be -5\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.log_alpha = self.log_sigma * 2.0 - 2.0 * torch.log(1e-16 + torch.abs(self.W))  # self.log_alpha is actually the dropout rate for each element\n",
    "        self.log_alpha = torch.clamp(self.log_alpha, -10, 10)  # this is equivalent to tf.clip_by_value\n",
    "        \n",
    "        if self.training:\n",
    "            lrt_mean = F.linear(x, self.W) + self.bias\n",
    "            lrt_std = torch.sqrt(F.linear(x * x, torch.exp(self.log_sigma * 2.0)) + 1e-8)\n",
    "            eps = lrt_std.data.new(lrt_std.size()).normal_()\n",
    "            return lrt_mean + lrt_std * eps\n",
    "    \n",
    "        return F.linear(x, self.W * (self.log_alpha < 3).float()) + self.bias\n",
    "    \n",
    "    def kl_reg(self):\n",
    "        \"\"\"This function returns the KL divergence\"\"\"\n",
    "        k1, k2, k3 = torch.Tensor([0.63576]).cuda(), torch.Tensor([1.8732]).cuda(), torch.Tensor([1.48695]).cuda()\n",
    "        kl = k1 * torch.sigmoid(k2 + k3 * self.log_alpha) - 0.5 * torch.log1p(torch.exp(-self.log_alpha))\n",
    "        a = -torch.sum(kl)\n",
    "        return a        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DSVDO(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                 dilation=1, groups=1, ard_init=-10, threshold=3):\n",
    "#         super(Conv2DSVDO, self).__init__(in_channels, out_channels, kernel_size, stride, \n",
    "#                                          padding, dilation, groups)\n",
    "#        self.bias=None\n",
    "        super(Conv2DSVDO, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.ard_init = ard_init  #  I think this parameter is for cliping\n",
    "        self.stride = stride\n",
    "        self.padding=padding\n",
    "        self.dilation=dilation\n",
    "        self.groups=groups\n",
    "        \n",
    "        kh, kw = kernel_size, kernel_size\n",
    "        self.W = Parameter(torch.Tensor(out_channels, in_channels, kh, kw))\n",
    "        self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        self.log_sigma = Parameter(torch.Tensor(out_channels, in_channels, kh, kw))\n",
    "        \n",
    "        print(\"The weight matrix\", self.W.shape)\n",
    "        print(\"The bias shape\", self.bias.shape)\n",
    "        print(\"The logsigma shape\", self.log_sigma.shape)\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.bias.data.zero_()\n",
    "        self.W.data.normal_(0, 0.02)\n",
    "        self.log_sigma.data.fill_(-5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        eps = 1e-8\n",
    "        self.log_alpha = self.log_sigma * 2.0 - 2.0 * torch.log(torch.abs(self.W) + 1e-16)\n",
    "        self.log_alpha = torch.clamp(self.log_alpha, -10.0, 10.0)\n",
    "        \n",
    "        if self.training:\n",
    "            conv_mu = F.conv2d(x, self.W, self.bias, self.stride, self.padding, \n",
    "                               self.dilation, self.groups)\n",
    "            conv_std = torch.sqrt(F.conv2d(x * x, torch.exp(self.log_sigma * 2.0)) + eps)\n",
    "            noise = torch.normal(torch.zeros_like(conv_mu), torch.ones_like(conv_std))\n",
    "            conv = conv_mu + conv_std * noise\n",
    "            return conv\n",
    "        \n",
    "        \n",
    "        return F.conv2d(x, self.W * (self.log_alpha < self.threshold).float(), self.bias,\n",
    "                        self.stride, self.padding, self.dilation, self.groups)\n",
    "    def kl_reg(self):\n",
    "        k1, k2, k3 = torch.Tensor([0.63576]).cuda(), torch.Tensor([1.8732]).cuda(), torch.Tensor([1.48695]).cuda()\n",
    "        kl = k1 * torch.sigmoid(k2 + k3 * self.log_alpha) - 0.5 * torch.log1p(torch.exp(-self.log_alpha))\n",
    "        a = -torch.sum(kl)\n",
    "        return a            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = LinearSVDO(28*28, 300, threshold)\n",
    "        self.fc2 = LinearSVDO(300, 100, threshold)\n",
    "        self.fc3 = LinearSVDO(100, 10, threshold)\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DNet(nn.Module):\n",
    "    def __init__(self, threshold):\n",
    "        super(Conv2DNet, self).__init__()\n",
    "        self.threshold = threshold\n",
    "        self.conv0 = Conv2DSVDO(1, 20, 5)\n",
    "        self.conv1 = Conv2DSVDO(20, 50, 5)\n",
    "        \n",
    "        self.fc1 = LinearSVDO(50*4*4, 300, threshold)\n",
    "        self.fc2 = LinearSVDO(300, 10, threshold)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "#        print(\"----first conv layer\", x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "#        print(\"----second conv layer\", x.shape)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "#        print(\"----first fc layer\", x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "#        print(\"----second fc layer\", x.shape)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for loading the dataset\n",
    "def get_mnist(batch_size):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_loader = torch.utils.data.DataLoader(datasets.MNIST('./data', train=True, download=True, \n",
    "                                                             transform=transform), batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(datasets.MNIST('./data', train=False, download=True, \n",
    "                                                            transform=transform), batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGVLB(nn.Module):\n",
    "    def __init__(self, net, train_size):\n",
    "        super(SGVLB, self).__init__()\n",
    "        self.train_size = train_size\n",
    "        self.net = net\n",
    "        \n",
    "    def forward(self, input, target, kl_weight=1.0):\n",
    "        assert not target.requires_grad\n",
    "        kl = 0.0\n",
    "        for module in self.net.children():\n",
    "#            print(module)\n",
    "            if hasattr(module, 'kl_reg'):\n",
    "                kl = kl + module.kl_reg()\n",
    "        return F.cross_entropy(input, target) * self.train_size + kl_weight * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight matrix torch.Size([20, 1, 5, 5])\n",
      "The bias shape torch.Size([20])\n",
      "The logsigma shape torch.Size([20, 1, 5, 5])\n",
      "The weight matrix torch.Size([50, 20, 5, 5])\n",
      "The bias shape torch.Size([50])\n",
      "The logsigma shape torch.Size([50, 20, 5, 5])\n",
      "The weight matrix torch.Size([300, 800])\n",
      "The log sigma torch.Size([300, 800])\n",
      "The bias term torch.Size([1, 300])\n",
      "The weight matrix torch.Size([10, 300])\n",
      "The log sigma torch.Size([10, 300])\n",
      "The bias term torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "if CONV2D is True:\n",
    "    model = Conv2DNet(threshold=3).cuda()\n",
    "else:\n",
    "    model = Net(threshold=3).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 60, 70, 80], \n",
    "                                                gamma=0.2)\n",
    "train_loader, test_loader = get_mnist(batch_size=100)\n",
    "sgvlb = SGVLB(model, len(train_loader.dataset)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight matrix torch.Size([300, 784])\n",
      "The log sigma torch.Size([300, 784])\n",
      "The bias term torch.Size([1, 300])\n",
      "The weight matrix torch.Size([100, 300])\n",
      "The log sigma torch.Size([100, 300])\n",
      "The bias term torch.Size([1, 100])\n",
      "The weight matrix torch.Size([10, 100])\n",
      "The log sigma torch.Size([10, 100])\n",
      "The bias term torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# model = Net(threshold=3).cuda()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 60, 70, 80], \n",
    "#                                                 gamma=0.2)\n",
    "# # fmt = {\"tr_loss\": '3.1e', \"te_loss\": \"3.1e\", \"sp_0\": \".3f\", \"sp_1\": \".3f\", \"lr\":\"3.1e\", \"kl\":\".2f\"}\n",
    "# # logger = Logger(\"sparse_vd\", fmt=fmt)\n",
    "\n",
    "# train_loader, test_loader = get_mnist(batch_size=100)\n",
    "# sgvlb = SGVLB(model, len(train_loader.dataset)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1, 5, 5)\n",
      "(50, 20, 5, 5)\n",
      "(300, 800)\n",
      "(10, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_use_conv0 = model.conv0.W.cpu().detach().numpy()\n",
    "w_use_conv1 = model.conv1.W.cpu().detach().numpy()\n",
    "w_use_fc0 = model.fc1.W.cpu().detach().numpy()\n",
    "w_use_fc1 = model.fc2.W.cpu().detach().numpy()\n",
    "group = [w_use_conv0, w_use_conv1, w_use_fc0, w_use_fc1]\n",
    "[print(v.shape) for v in group]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 trlos 227.264 tracc 87.232 valos 18.966 valacc 98.070  0.01 0.12 0.41 0.09 time 13.762\n",
      "epoch 2 trlos-15.424 tracc 98.207 valos-38.794 valacc 98.700  0.03 0.26 0.58 0.13 time 14.473\n",
      "epoch 3 trlos-65.177 tracc 98.480 valos-80.467 valacc 98.810  0.03 0.37 0.69 0.17 time 15.731\n",
      "epoch 4 trlos-109.354 tracc 98.818 valos-121.362 valacc 98.980  0.06 0.47 0.75 0.21 time 15.914\n",
      "epoch 5 trlos-146.817 tracc 98.788 valos-150.556 valacc 98.820  0.06 0.51 0.76 0.24 time 15.171\n",
      "epoch 6 trlos-184.531 tracc 98.928 valos-186.870 valacc 98.900  0.07 0.55 0.79 0.27 time 15.766\n",
      "epoch 7 trlos-220.764 tracc 98.940 valos-226.872 valacc 99.070  0.14 0.62 0.84 0.33 time 14.965\n",
      "epoch 8 trlos-256.723 tracc 99.005 valos-258.985 valacc 98.840  0.14 0.64 0.85 0.34 time 12.393\n",
      "epoch 9 trlos-291.590 tracc 99.010 valos-293.901 valacc 99.090  0.21 0.65 0.86 0.33 time 15.960\n",
      "epoch 10 trlos-326.124 tracc 99.058 valos-331.300 valacc 99.130  0.24 0.68 0.89 0.38 time 15.837\n",
      "epoch 11 trlos-361.324 tracc 99.045 valos-362.455 valacc 99.000  0.22 0.68 0.89 0.38 time 14.730\n",
      "epoch 12 trlos-396.161 tracc 99.107 valos-397.223 valacc 99.130  0.26 0.72 0.90 0.41 time 15.586\n",
      "epoch 13 trlos-430.644 tracc 99.140 valos-433.672 valacc 99.180  0.29 0.74 0.92 0.41 time 14.822\n",
      "epoch 14 trlos-464.423 tracc 99.092 valos-464.271 valacc 99.080  0.26 0.71 0.90 0.38 time 16.099\n",
      "epoch 15 trlos-499.205 tracc 99.107 valos-501.814 valacc 99.210  0.31 0.73 0.92 0.42 time 15.922\n",
      "epoch 16 trlos-533.831 tracc 99.137 valos-534.790 valacc 99.180  0.36 0.75 0.92 0.43 time 15.714\n",
      "epoch 17 trlos-568.056 tracc 99.163 valos-570.421 valacc 99.230  0.38 0.77 0.94 0.46 time 15.418\n",
      "epoch 18 trlos-601.728 tracc 99.115 valos-601.091 valacc 99.040  0.38 0.78 0.94 0.46 time 15.076\n",
      "epoch 19 trlos-634.479 tracc 99.023 valos-635.760 valacc 99.110  0.35 0.76 0.93 0.46 time 16.850\n",
      "epoch 20 trlos-670.702 tracc 99.157 valos-672.192 valacc 99.220  0.35 0.78 0.95 0.52 time 15.107\n",
      "epoch 21 trlos-704.147 tracc 99.112 valos-706.264 valacc 99.180  0.41 0.79 0.95 0.52 time 15.462\n",
      "epoch 22 trlos-738.356 tracc 99.132 valos-738.535 valacc 99.050  0.37 0.80 0.95 0.53 time 16.747\n",
      "epoch 23 trlos-772.579 tracc 99.132 valos-771.850 valacc 99.080  0.37 0.81 0.95 0.51 time 14.844\n",
      "epoch 24 trlos-806.642 tracc 99.132 valos-809.872 valacc 99.210  0.41 0.82 0.96 0.56 time 14.200\n",
      "epoch 25 trlos-839.086 tracc 99.053 valos-841.068 valacc 99.120  0.39 0.81 0.95 0.55 time 17.100\n",
      "epoch 26 trlos-874.987 tracc 99.137 valos-876.542 valacc 99.150  0.38 0.83 0.96 0.58 time 16.400\n",
      "epoch 27 trlos-908.516 tracc 99.110 valos-909.342 valacc 99.080  0.41 0.83 0.96 0.59 time 15.417\n",
      "epoch 28 trlos-941.834 tracc 99.097 valos-944.548 valacc 99.150  0.40 0.83 0.96 0.60 time 16.282\n",
      "epoch 29 trlos-976.824 tracc 99.148 valos-976.461 valacc 99.140  0.41 0.84 0.96 0.61 time 15.498\n",
      "epoch 30 trlos-1009.778 tracc 99.083 valos-1013.475 valacc 99.210  0.43 0.84 0.97 0.65 time 16.996\n",
      "epoch 31 trlos-1045.336 tracc 99.132 valos-1047.928 valacc 99.190  0.45 0.85 0.97 0.68 time 16.648\n",
      "epoch 32 trlos-1078.117 tracc 99.117 valos-1080.846 valacc 99.260  0.43 0.84 0.97 0.63 time 15.510\n",
      "epoch 33 trlos-1113.346 tracc 99.117 valos-1114.492 valacc 99.310  0.42 0.85 0.97 0.63 time 16.553\n",
      "epoch 34 trlos-1146.169 tracc 99.052 valos-1148.454 valacc 99.160  0.43 0.85 0.97 0.67 time 16.745\n",
      "epoch 35 trlos-1179.968 tracc 99.082 valos-1182.267 valacc 99.250  0.44 0.85 0.97 0.65 time 16.443\n",
      "epoch 36 trlos-1213.972 tracc 99.073 valos-1216.140 valacc 99.250  0.40 0.86 0.97 0.69 time 16.433\n",
      "epoch 37 trlos-1248.818 tracc 99.127 valos-1250.822 valacc 99.220  0.43 0.86 0.97 0.70 time 15.806\n",
      "epoch 38 trlos-1281.577 tracc 99.060 valos-1285.115 valacc 99.270  0.42 0.87 0.97 0.72 time 15.638\n",
      "epoch 39 trlos-1315.085 tracc 99.050 valos-1319.316 valacc 99.300  0.45 0.86 0.98 0.73 time 15.760\n",
      "epoch 40 trlos-1348.682 tracc 99.048 valos-1354.490 valacc 99.310  0.45 0.87 0.98 0.76 time 16.078\n",
      "epoch 41 trlos-1382.807 tracc 99.027 valos-1386.425 valacc 99.170  0.45 0.87 0.98 0.75 time 15.768\n",
      "epoch 42 trlos-1417.484 tracc 99.067 valos-1421.942 valacc 99.270  0.42 0.88 0.98 0.76 time 15.522\n",
      "epoch 43 trlos-1451.060 tracc 99.067 valos-1455.019 valacc 99.180  0.45 0.88 0.98 0.76 time 16.601\n",
      "epoch 44 trlos-1485.519 tracc 99.042 valos-1486.229 valacc 99.130  0.42 0.87 0.98 0.76 time 15.338\n",
      "epoch 45 trlos-1519.515 tracc 99.075 valos-1523.855 valacc 99.240  0.44 0.88 0.98 0.79 time 16.593\n",
      "epoch 46 trlos-1553.401 tracc 99.037 valos-1556.346 valacc 99.190  0.46 0.88 0.98 0.78 time 16.987\n",
      "epoch 47 trlos-1587.152 tracc 99.073 valos-1590.307 valacc 99.170  0.44 0.88 0.98 0.79 time 15.722\n",
      "epoch 48 trlos-1620.424 tracc 99.023 valos-1624.537 valacc 99.210  0.45 0.88 0.98 0.79 time 16.417\n",
      "epoch 49 trlos-1654.718 tracc 99.047 valos-1657.945 valacc 99.210  0.43 0.88 0.98 0.78 time 15.818\n",
      "epoch 50 trlos-1655.369 tracc 99.053 valos-1659.806 valacc 99.270  0.46 0.89 0.98 0.81 time 14.631\n",
      "epoch 51 trlos-1659.349 tracc 99.100 valos-1663.072 valacc 99.290  0.53 0.92 0.99 0.87 time 16.777\n",
      "epoch 52 trlos-1661.945 tracc 99.202 valos-1663.438 valacc 99.350  0.54 0.92 0.99 0.88 time 14.755\n",
      "epoch 53 trlos-1661.892 tracc 99.215 valos-1663.798 valacc 99.340  0.55 0.93 0.99 0.89 time 16.110\n",
      "epoch 54 trlos-1662.030 tracc 99.210 valos-1663.866 valacc 99.320  0.56 0.93 0.99 0.89 time 15.714\n",
      "epoch 55 trlos-1662.702 tracc 99.235 valos-1663.764 valacc 99.290  0.56 0.93 0.99 0.88 time 16.691\n",
      "epoch 56 trlos-1663.067 tracc 99.243 valos-1664.410 valacc 99.360  0.56 0.93 0.99 0.88 time 16.484\n",
      "epoch 57 trlos-1663.159 tracc 99.233 valos-1664.173 valacc 99.290  0.54 0.93 0.99 0.89 time 16.407\n",
      "epoch 58 trlos-1662.996 tracc 99.235 valos-1664.410 valacc 99.310  0.55 0.93 0.99 0.89 time 15.372\n",
      "epoch 59 trlos-1662.663 tracc 99.205 valos-1664.590 valacc 99.300  0.55 0.93 0.99 0.89 time 15.163\n",
      "epoch 60 trlos-1663.156 tracc 99.235 valos-1664.523 valacc 99.340  0.54 0.93 0.99 0.89 time 15.803\n"
     ]
    }
   ],
   "source": [
    "kl_weight = 0.02\n",
    "epochs = 60\n",
    "W_group = [[] for i in range(4)]\n",
    "val_accu = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    kl_weight = min(kl_weight+0.02, 1)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if CONV2D is True:\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "        else:\n",
    "            data = data.view(-1, 28*28)\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        pred = output.data.max(1)[1]\n",
    "        loss = sgvlb(output, target, kl_weight)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss\n",
    "        train_acc += np.sum(pred.cpu().numpy() == target.cpu().data.numpy())\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0.0, 0.0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if CONV2D is True:\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "        else:\n",
    "            data = data.view(-1, 28*28)\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "        output = model(data)\n",
    "        test_loss += float(sgvlb(output, target, kl_weight))\n",
    "        pred = output.data.max(1)[1]\n",
    "        test_acc += np.sum(pred.cpu().numpy() == target.cpu().data.numpy())\n",
    "    if epoch % 2 == 0 or epoch == epochs:\n",
    "        for c_iter, c in enumerate(model.children()):\n",
    "            W_group[c_iter].append(c.log_alpha.cpu().data.numpy())\n",
    "        val_accu.append(test_acc / len(test_loader.dataset) * 100)\n",
    "    end = time.time()\n",
    "    \n",
    "    loss_vec = [\"epoch\", epoch, \"trlos\", train_loss/len(train_loader.dataset), \n",
    "                \"tracc\", train_acc/len(train_loader.dataset) * 100,\n",
    "                \"valos\", test_loss/ len(test_loader.dataset), \n",
    "                \"valacc\", test_acc/ len(test_loader.dataset) * 100]\n",
    "    for i, c in enumerate(model.children()):\n",
    "        if hasattr(c, 'kl_reg'):\n",
    "            loss_vec.append((c.log_alpha.cpu().data.numpy() > model.threshold).mean())\n",
    "    loss_vec.append(\"time\")\n",
    "    loss_vec.append(end-start)\n",
    "    \n",
    "    if CONV2D is True:\n",
    "        print(\"{:s}{: d} {:s}{: .3f} {:s}{: .3f} {:s}{: .3f} {:s}{: .3f} {: .2f}{: .2f}{: .2f}{: .2f} {:s}{: .3f}\".format(*loss_vec))          \n",
    "    else:\n",
    "        print(\"{:s}{: d} {:s}{: .3f} {:s}{: .3f} {:s}{: .3f} {:s}{: .3f} {: .2f}{: .2f}{: .2f} {:s}{: .3f}\".format(*loss_vec))          \n",
    "    \n",
    "    scheduler.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the kept weight ratio is 1.753\n"
     ]
    }
   ],
   "source": [
    "all_w, kep_w = 0, 0\n",
    "for c in model.children():\n",
    "    kep_w += (c.log_alpha.cpu().data.numpy() < model.threshold).sum()\n",
    "    all_w += c.log_alpha.cpu().data.numpy().size\n",
    "print(\"the kept weight ratio is %.3f\" % (kep_w / all_w * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animation(save_name, feature, rate, test_accu):\n",
    "    save_dir = '/project/bo/exp_data/'\n",
    "    with imageio.get_writer(save_dir + '/%s.gif' % save_name, mode='I', fps=5) as writer:\n",
    "        for iterr, single_feature in enumerate(feature):\n",
    "            fig = plt.figure(figsize=(4,2.5))\n",
    "            ax = fig.add_subplot(111)\n",
    "            sns.heatmap(abs(single_feature), cmap='Reds')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            ax.set_title(\"epoch %d sparsity %.2f test accuracy %.2f\" % (iterr * 2, rate[iterr] * 100, test_accu[iterr]), fontsize=6)\n",
    "            plt.savefig(save_dir + '/im.png', pad_inches=0, bbox_inches='tight', dpi=300)\n",
    "            plt.close()\n",
    "            im = cv2.imread(save_dir + '/im.png')[:, :, ::-1]\n",
    "            writer.append_data(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_canvas(feature):\n",
    "    \"\"\"This function is used to create canvas\n",
    "    Args: \n",
    "        feature [out_channel, in_channel, kh, kw]\n",
    "    \"\"\"\n",
    "    nx, ny, fh, fw = np.shape(feature)\n",
    "    x_values = np.linspace(-3, 3, nx)\n",
    "    y_values = np.linspace(-3, 3, ny)\n",
    "    canvas = np.empty((fw * nx, fh * ny))\n",
    "    \n",
    "    for i, yi in enumerate(x_values):\n",
    "        f_sub = feature[i]\n",
    "        for j, xj in enumerate(y_values):\n",
    "            f_use = f_sub[j]\n",
    "#             f_use[:, -1] = 10.0\n",
    "#             f_use[:, 0] = 10.0\n",
    "#             f_use[-1, :] = 10.0\n",
    "#             f_use[0, :] = 10.0\n",
    "            canvas[(nx - i - 1) * fh:(nx - i) * fh,\n",
    "                   j * fw:(j + 1) * fw] = f_use        \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iterr, save_feature in enumerate(W_group):\n",
    "    num_dim = np.shape(save_feature[0])\n",
    "    num_element_tot = np.prod(num_dim)\n",
    "    rate = [np.sum((v >= model.threshold).astype('int32')) / num_element_tot for v in save_feature]\n",
    "    save_feature = [v * (v < model.threshold).astype('int32') for v in save_feature]\n",
    "    if len(num_dim) == 4:\n",
    "        save_name = \"feature_conv_%d\" % iterr\n",
    "        save_feature = [create_canvas(v) for v in save_feature]\n",
    "    elif len(num_dim) == 2:\n",
    "        save_name = \"feature_fc_%d\" % iterr\n",
    "    generate_animation(save_name, save_feature, rate, val_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iterr, save_feature in enumerate(W_group):\n",
    "    save_name = \"feature_anim_%d\" % iterr\n",
    "    num_element_tot = np.prod(np.shape(save_feature[0]))\n",
    "    rate = [np.sum((v >= model.threshold).astype('int32')) / num_element_tot for v in save_feature]\n",
    "    save_feature = [v * (v < model.threshold).astype('int32') for v in save_feature]\n",
    "    generate_animation(save_name, save_feature, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
